{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f258886-a39d-4137-b776-16db3814be90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from typing import Optional, Dict, Any, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3023e73c-1d6b-4cb1-b2cd-f27d7e63df58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class AzureFineTuner:\n",
    "    \"\"\"\n",
    "    Comprehensive Azure OpenAI fine-tuning manager for TLOF models.\n",
    "    Handles the complete workflow from data upload to model deployment.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize Azure OpenAI client with environment variables\"\"\"\n",
    "        load_dotenv()\n",
    "        \n",
    "        # Validate environment variables\n",
    "        required_vars = [\n",
    "            \"AZURE_OPENAI_API_KEY\",\n",
    "            \"AZURE_OPENAI_ENDPOINT\"\n",
    "        ]\n",
    "        \n",
    "        missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "        if missing_vars:\n",
    "            raise ValueError(f\"Missing required environment variables: {missing_vars}\")\n",
    "        \n",
    "        self.client = AzureOpenAI(\n",
    "            api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "            api_version=\"2024-02-01\",  # Latest API version for fine-tuning\n",
    "            azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "        )\n",
    "        \n",
    "        logger.info(\"✅ Azure OpenAI client initialized successfully\")\n",
    "    \n",
    "    def upload_training_file(self, file_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Upload training data file to Azure OpenAI\n",
    "        \n",
    "        Args:\n",
    "            file_path: Path to the JSONL training file\n",
    "            \n",
    "        Returns:\n",
    "            File ID for the uploaded file\n",
    "        \"\"\"\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"Training file not found: {file_path}\")\n",
    "        \n",
    "        # Validate file size (Azure has limits)\n",
    "        file_size = os.path.getsize(file_path)\n",
    "        max_size = 100 * 1024 * 1024  # 100MB limit\n",
    "        \n",
    "        if file_size > max_size:\n",
    "            raise ValueError(f\"File too large: {file_size/1024/1024:.1f}MB (max: 100MB)\")\n",
    "        \n",
    "        logger.info(f\"📤 Uploading training file: {file_path} ({file_size/1024/1024:.1f}MB)\")\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, 'rb') as f:\n",
    "                response = self.client.files.create(\n",
    "                    file=f,\n",
    "                    purpose=\"fine-tune\"\n",
    "                )\n",
    "            \n",
    "            logger.info(f\"✅ File uploaded successfully. File ID: {response.id}\")\n",
    "            return response.id\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"❌ Failed to upload file: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def list_uploaded_files(self) -> List[Dict]:\n",
    "        \"\"\"List all uploaded files for fine-tuning\"\"\"\n",
    "        try:\n",
    "            files = self.client.files.list(purpose=\"fine-tune\")\n",
    "            return [{\"id\": f.id, \"filename\": f.filename, \"created\": f.created_at} for f in files.data]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"❌ Failed to list files: {str(e)}\")\n",
    "            return []\n",
    "    \n",
    "    def create_fine_tuning_job(self, training_file_id: str, \n",
    "                              base_model: str = \"gpt-3.5-turbo\",\n",
    "                              validation_file_id: Optional[str] = None,\n",
    "                              hyperparameters: Optional[Dict] = None) -> str:\n",
    "        \"\"\"\n",
    "        Create a fine-tuning job with advanced configuration\n",
    "        \n",
    "        Args:\n",
    "            training_file_id: ID of uploaded training file\n",
    "            base_model: Base model to fine-tune\n",
    "            validation_file_id: Optional validation file ID\n",
    "            hyperparameters: Custom hyperparameters\n",
    "            \n",
    "        Returns:\n",
    "            Fine-tuning job ID\n",
    "        \"\"\"\n",
    "        if hyperparameters is None:\n",
    "            hyperparameters = {\n",
    "                \"n_epochs\": 3,  # Number of training epochs\n",
    "                \"batch_size\": 1,  # Batch size (1-256)\n",
    "                \"learning_rate_multiplier\": 0.1  # Learning rate multiplier\n",
    "            }\n",
    "        \n",
    "        logger.info(f\"🚀 Creating fine-tuning job with base model: {base_model}\")\n",
    "        logger.info(f\"📊 Hyperparameters: {hyperparameters}\")\n",
    "        \n",
    "        try:\n",
    "            job_params = {\n",
    "                \"training_file\": training_file_id,\n",
    "                \"model\": base_model,\n",
    "                \"hyperparameters\": hyperparameters\n",
    "            }\n",
    "            \n",
    "            # Add validation file if provided\n",
    "            if validation_file_id:\n",
    "                job_params[\"validation_file\"] = validation_file_id\n",
    "                logger.info(f\"📋 Using validation file: {validation_file_id}\")\n",
    "            \n",
    "            response = self.client.fine_tuning.jobs.create(**job_params)\n",
    "            \n",
    "            logger.info(f\"✅ Fine-tuning job created successfully!\")\n",
    "            logger.info(f\"📝 Job ID: {response.id}\")\n",
    "            logger.info(f\"📊 Status: {response.status}\")\n",
    "            \n",
    "            return response.id\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"❌ Failed to create fine-tuning job: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def monitor_fine_tuning(self, job_id: str, check_interval: int = 60) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Monitor fine-tuning job progress with detailed status updates\n",
    "        \n",
    "        Args:\n",
    "            job_id: Fine-tuning job ID\n",
    "            check_interval: How often to check status (seconds)\n",
    "            \n",
    "        Returns:\n",
    "            Fine-tuned model name if successful, None if failed\n",
    "        \"\"\"\n",
    "        logger.info(f\"👀 Monitoring fine-tuning job: {job_id}\")\n",
    "        logger.info(f\"⏱️  Checking every {check_interval} seconds...\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        last_status = None\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                job = self.client.fine_tuning.jobs.retrieve(job_id)\n",
    "                status = job.status\n",
    "                \n",
    "                # Log status changes\n",
    "                if status != last_status:\n",
    "                    elapsed = time.time() - start_time\n",
    "                    logger.info(f\"📊 Status: {status} (Elapsed: {elapsed/60:.1f} minutes)\")\n",
    "                    last_status = status\n",
    "                \n",
    "                # Check for completion\n",
    "                if status == \"succeeded\":\n",
    "                    elapsed = time.time() - start_time\n",
    "                    logger.info(f\"🎉 Fine-tuning completed successfully!\")\n",
    "                    logger.info(f\"⏱️  Total time: {elapsed/60:.1f} minutes\")\n",
    "                    logger.info(f\"🤖 Fine-tuned model: {job.fine_tuned_model}\")\n",
    "                    \n",
    "                    # Log training metrics if available\n",
    "                    if hasattr(job, 'result_files') and job.result_files:\n",
    "                        logger.info(\"📈 Training completed with metrics available\")\n",
    "                    \n",
    "                    return job.fine_tuned_model\n",
    "                \n",
    "                elif status == \"failed\":\n",
    "                    logger.error(f\"❌ Fine-tuning failed!\")\n",
    "                    if hasattr(job, 'error') and job.error:\n",
    "                        logger.error(f\"💥 Error details: {job.error}\")\n",
    "                    return None\n",
    "                \n",
    "                elif status in [\"cancelled\", \"validating_files\"]:\n",
    "                    logger.warning(f\"⚠️  Job status: {status}\")\n",
    "                    return None\n",
    "                \n",
    "                # Wait before next check\n",
    "                time.sleep(check_interval)\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                logger.info(\"🛑 Monitoring interrupted by user\")\n",
    "                return None\n",
    "            except Exception as e:\n",
    "                logger.error(f\"❌ Error monitoring job: {str(e)}\")\n",
    "                time.sleep(check_interval)\n",
    "    \n",
    "    def list_fine_tuning_jobs(self, limit: int = 10) -> List[Dict]:\n",
    "        \"\"\"List recent fine-tuning jobs\"\"\"\n",
    "        try:\n",
    "            jobs = self.client.fine_tuning.jobs.list(limit=limit)\n",
    "            return [{\n",
    "                \"id\": job.id,\n",
    "                \"model\": job.model,\n",
    "                \"status\": job.status,\n",
    "                \"created_at\": job.created_at,\n",
    "                \"fine_tuned_model\": getattr(job, 'fine_tuned_model', None)\n",
    "            } for job in jobs.data]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"❌ Failed to list jobs: {str(e)}\")\n",
    "            return []\n",
    "    \n",
    "    def test_fine_tuned_model(self, model_name: str, test_prompts: List[str]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Test the fine-tuned model with sample prompts\n",
    "        \n",
    "        Args:\n",
    "            model_name: Name of the fine-tuned model\n",
    "            test_prompts: List of test prompts\n",
    "            \n",
    "        Returns:\n",
    "            List of test results\n",
    "        \"\"\"\n",
    "        logger.info(f\"🧪 Testing fine-tuned model: {model_name}\")\n",
    "        results = []\n",
    "        \n",
    "        for i, prompt in enumerate(test_prompts, 1):\n",
    "            logger.info(f\"📝 Test {i}/{len(test_prompts)}: {prompt[:50]}...\")\n",
    "            \n",
    "            try:\n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=model_name,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are a TLOF configuration generator. Generate valid JSON for TLOF specifications based on natural language descriptions.\"},\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ],\n",
    "                    max_tokens=2000,\n",
    "                    temperature=0.3\n",
    "                )\n",
    "                \n",
    "                result = {\n",
    "                    \"prompt\": prompt,\n",
    "                    \"response\": response.choices[0].message.content,\n",
    "                    \"success\": True\n",
    "                }\n",
    "                \n",
    "                # Try to validate JSON response\n",
    "                try:\n",
    "                    json.loads(result[\"response\"])\n",
    "                    result[\"valid_json\"] = True\n",
    "                except json.JSONDecodeError:\n",
    "                    result[\"valid_json\"] = False\n",
    "                    logger.warning(f\"⚠️  Test {i} produced invalid JSON\")\n",
    "                \n",
    "                results.append(result)\n",
    "                logger.info(f\"✅ Test {i} completed\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"❌ Test {i} failed: {str(e)}\")\n",
    "                results.append({\n",
    "                    \"prompt\": prompt,\n",
    "                    \"response\": f\"Error: {str(e)}\",\n",
    "                    \"success\": False,\n",
    "                    \"valid_json\": False\n",
    "                })\n",
    "        \n",
    "        # Summary\n",
    "        successful_tests = sum(1 for r in results if r[\"success\"])\n",
    "        valid_json_tests = sum(1 for r in results if r.get(\"valid_json\", False))\n",
    "        \n",
    "        logger.info(f\"📊 Test Results Summary:\")\n",
    "        logger.info(f\"   Successful responses: {successful_tests}/{len(test_prompts)}\")\n",
    "        logger.info(f\"   Valid JSON responses: {valid_json_tests}/{len(test_prompts)}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def delete_fine_tuning_files(self, file_ids: List[str]) -> None:\n",
    "        \"\"\"Clean up uploaded files\"\"\"\n",
    "        for file_id in file_ids:\n",
    "            try:\n",
    "                self.client.files.delete(file_id)\n",
    "                logger.info(f\"🗑️  Deleted file: {file_id}\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"⚠️  Failed to delete file {file_id}: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main fine-tuning workflow\n",
    "    \"\"\"\n",
    "    print(\"🚀 Azure OpenAI Fine-tuning for TLOF Models\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # Initialize fine-tuner\n",
    "        tuner = AzureFineTuner()\n",
    "        \n",
    "        # Configuration\n",
    "        training_file = \"tlof_training_data.jsonl\"\n",
    "        validation_file = \"tlof_validation_data.jsonl\"\n",
    "        base_model = \"gpt-3.5-turbo\"  # Use gpt-4 if available in your region\n",
    "        \n",
    "        # Check if training files exist\n",
    "        if not os.path.exists(training_file):\n",
    "            logger.error(f\"❌ Training file not found: {training_file}\")\n",
    "            logger.info(\"🔧 Please run 'python training_data_generator.py' first!\")\n",
    "            return\n",
    "        \n",
    "        # Step 1: Upload training file\n",
    "        logger.info(\"📤 Step 1: Uploading training data...\")\n",
    "        training_file_id = tuner.upload_training_file(training_file)\n",
    "        \n",
    "        # Step 2: Upload validation file (optional)\n",
    "        validation_file_id = None\n",
    "        if os.path.exists(validation_file):\n",
    "            logger.info(\"📤 Step 2: Uploading validation data...\")\n",
    "            validation_file_id = tuner.upload_training_file(validation_file)\n",
    "        else:\n",
    "            logger.warning(\"⚠️  No validation file found, proceeding without validation\")\n",
    "        \n",
    "        # Step 3: Create fine-tuning job with custom hyperparameters\n",
    "        logger.info(\"🚀 Step 3: Creating fine-tuning job...\")\n",
    "        \n",
    "        # Advanced hyperparameters for better results\n",
    "        hyperparameters = {\n",
    "            \"n_epochs\": 3,  # More epochs for better learning\n",
    "            \"batch_size\": 1,  # Small batch size for stability\n",
    "            \"learning_rate_multiplier\": 0.1  # Conservative learning rate\n",
    "        }\n",
    "        \n",
    "        job_id = tuner.create_fine_tuning_job(\n",
    "            training_file_id=training_file_id,\n",
    "            base_model=base_model,\n",
    "            validation_file_id=validation_file_id,\n",
    "            hyperparameters=hyperparameters\n",
    "        )\n",
    "        \n",
    "        # Step 4: Monitor progress\n",
    "        logger.info(\"👀 Step 4: Monitoring training progress...\")\n",
    "        fine_tuned_model = tuner.monitor_fine_tuning(job_id, check_interval=60)\n",
    "        \n",
    "        if fine_tuned_model:\n",
    "            # Step 5: Test the model\n",
    "            logger.info(\"🧪 Step 5: Testing fine-tuned model...\")\n",
    "            \n",
    "            test_prompts = [\n",
    "                \"Generate a rectangular TLOF for a helicopter with 25m x 30m dimensions, elevation 10m, and blue 'H' landing marker.\",\n",
    "                \"Create a circular landing pad for an eVTOL with 20m diameter, white perimeter lighting, and safety area.\",\n",
    "                \"Design a polygon TLOF for a tiltrotor aircraft with 6 sides, 35m width, red 'V' marker, and dashed markings.\",\n",
    "                \"Build a simple rectangular TLOF for a drone with 8m x 8m dimensions at ground level.\"\n",
    "            ]\n",
    "            \n",
    "            test_results = tuner.test_fine_tuned_model(fine_tuned_model, test_prompts)\n",
    "            \n",
    "            # Step 6: Save results and cleanup\n",
    "            logger.info(\"💾 Step 6: Saving results...\")\n",
    "            \n",
    "            # Save test results\n",
    "            with open(\"fine_tuning_results.json\", \"w\") as f:\n",
    "                json.dump({\n",
    "                    \"model_name\": fine_tuned_model,\n",
    "                    \"job_id\": job_id,\n",
    "                    \"base_model\": base_model,\n",
    "                    \"hyperparameters\": hyperparameters,\n",
    "                    \"test_results\": test_results,\n",
    "                    \"timestamp\": time.time()\n",
    "                }, f, indent=2)\n",
    "            \n",
    "            # Success message\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"🎉 FINE-TUNING COMPLETED SUCCESSFULLY!\")\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"📝 Your fine-tuned model: {fine_tuned_model}\")\n",
    "            print(f\"📊 Job ID: {job_id}\")\n",
    "            print(f\"📋 Results saved to: fine_tuning_results.json\")\n",
    "            print(\"\\n🔧 To use this model in your application:\")\n",
    "            print(f\"   Set AZURE_OPENAI_FINETUNED_MODEL_NAME={fine_tuned_model}\")\n",
    "            print(f\"   Use 'python updated_tlof_model.py' to test it\")\n",
    "            print(\"\\n✨ Your model is now ready for production use!\")\n",
    "            \n",
    "            # Optional cleanup\n",
    "            cleanup = input(\"\\n🗑️  Delete uploaded training files? (y/N): \").strip().lower()\n",
    "            if cleanup == 'y':\n",
    "                files_to_delete = [training_file_id]\n",
    "                if validation_file_id:\n",
    "                    files_to_delete.append(validation_file_id)\n",
    "                tuner.delete_fine_tuning_files(files_to_delete)\n",
    "        \n",
    "        else:\n",
    "            logger.error(\"❌ Fine-tuning failed. Check the logs above for details.\")\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        logger.info(\"🛑 Process interrupted by user\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"💥 Unexpected error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
