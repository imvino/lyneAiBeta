{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f258886-a39d-4137-b776-16db3814be90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from typing import Optional, Dict, Any\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3023e73c-1d6b-4cb1-b2cd-f27d7e63df58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class TLOFGenerator:\n",
    "    \"\"\"\n",
    "    TLOF Generator using fine-tuned Azure OpenAI models.\n",
    "    Simplified approach without function calling - just natural language to JSON.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize with Azure OpenAI credentials\"\"\"\n",
    "        load_dotenv()\n",
    "        \n",
    "        # Validate environment variables\n",
    "        required_vars = [\"AZURE_OPENAI_API_KEY\", \"AZURE_OPENAI_ENDPOINT\"]\n",
    "        missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "        \n",
    "        if missing_vars:\n",
    "            raise ValueError(f\"Missing required environment variables: {missing_vars}\")\n",
    "        \n",
    "        self.client = AzureOpenAI(\n",
    "            api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "            api_version=\"2024-02-01\",\n",
    "            azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "        )\n",
    "        \n",
    "        # Model name prioritization: fine-tuned > base model\n",
    "        self.model_name = (\n",
    "            os.getenv(\"AZURE_OPENAI_FINETUNED_MODEL_NAME\") or \n",
    "            os.getenv(\"AZURE_OPENAI_MODEL_NAME\") or \n",
    "            \"gpt-3.5-turbo\"\n",
    "        )\n",
    "        \n",
    "        self.is_fine_tuned = bool(os.getenv(\"AZURE_OPENAI_FINETUNED_MODEL_NAME\"))\n",
    "        \n",
    "        logger.info(f\"‚úÖ TLOF Generator initialized\")\n",
    "        logger.info(f\"ü§ñ Using model: {self.model_name}\")\n",
    "        logger.info(f\"üîß Fine-tuned: {'Yes' if self.is_fine_tuned else 'No'}\")\n",
    "    \n",
    "    def generate_tlof_configuration(self, user_input: str, \n",
    "                                  temperature: float = 0.3,\n",
    "                                  max_tokens: int = 2000) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Generate TLOF configuration from natural language description\n",
    "        \n",
    "        Args:\n",
    "            user_input: Natural language description of TLOF requirements\n",
    "            temperature: Model temperature (0.0-1.0, lower = more consistent)\n",
    "            max_tokens: Maximum tokens in response\n",
    "            \n",
    "        Returns:\n",
    "            TLOF configuration dictionary or None if generation failed\n",
    "        \"\"\"\n",
    "        logger.info(f\"üöÄ Generating TLOF configuration...\")\n",
    "        logger.info(f\"üìù Input: {user_input[:100]}...\")\n",
    "        \n",
    "        try:\n",
    "            # Prepare messages based on whether we're using fine-tuned model\n",
    "            if self.is_fine_tuned:\n",
    "                # Fine-tuned model: simpler system prompt since it's trained on our data\n",
    "                messages = [\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You are a TLOF configuration generator. Generate valid JSON for TLOF specifications based on natural language descriptions.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": user_input\n",
    "                    }\n",
    "                ]\n",
    "            else:\n",
    "                # Base model: detailed system prompt with examples\n",
    "                system_prompt = self._get_enhanced_system_prompt()\n",
    "                messages = [\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": system_prompt\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": user_input\n",
    "                    }\n",
    "                ]\n",
    "            \n",
    "            # Generate response\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model_name,\n",
    "                messages=messages,\n",
    "                max_tokens=max_tokens,\n",
    "                temperature=temperature\n",
    "            )\n",
    "            \n",
    "            response_content = response.choices[0].message.content\n",
    "            logger.info(f\"‚úÖ Generated response ({len(response_content)} characters)\")\n",
    "            \n",
    "            # Parse and validate JSON\n",
    "            tlof_config = self._extract_and_validate_json(response_content)\n",
    "            \n",
    "            if tlof_config:\n",
    "                logger.info(\"üéâ Successfully generated valid TLOF configuration!\")\n",
    "                return tlof_config\n",
    "            else:\n",
    "                logger.error(\"‚ùå Failed to extract valid JSON from response\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"üí• Error generating TLOF configuration: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def _get_enhanced_system_prompt(self) -> str:\n",
    "        \"\"\"Get enhanced system prompt for base models (non-fine-tuned)\"\"\"\n",
    "        return \"\"\"You are a specialized TLOF (Touchdown and Lift-Off Area) configuration generator for aviation landing surfaces. Generate valid JSON configurations based on natural language descriptions.\n",
    "\n",
    "REQUIRED JSON STRUCTURE:\n",
    "{\n",
    "  \"TLOF\": [\n",
    "    {\n",
    "      \"position\": [longitude, latitude],\n",
    "      \"dimensions\": {\n",
    "        \"unit\": \"m\",\n",
    "        \"aircraftCategory\": false,\n",
    "        \"aircraft\": \"aircraft_type\",\n",
    "        \"diameter\": number,\n",
    "        \"isVisible\": true,\n",
    "        \"layerName\": \"Generated_TLOF\",\n",
    "        \"shapeType\": \"Rectangle|Circle|Polygon\",\n",
    "        \"scaleCategory\": false,\n",
    "        \"textureScaleU\": 1,\n",
    "        \"textureScaleV\": 1,\n",
    "        \"safetyNetScaleU\": 1,\n",
    "        \"safetyNetScaleV\": 1,\n",
    "        \"sides\": number,\n",
    "        \"width\": number,\n",
    "        \"length\": number,\n",
    "        \"height\": number,\n",
    "        \"rotation\": number,\n",
    "        \"transparency\": number,\n",
    "        \"baseHeight\": number,\n",
    "        \"markingsCategory\": boolean,\n",
    "        \"markingType\": \"solid|dashed\",\n",
    "        \"markingColor\": \"white|yellow|blue|red|green|black|purple|orange|gray|brown\",\n",
    "        \"markingThickness\": number,\n",
    "        \"dashDistance\": number,\n",
    "        \"dashLength\": number,\n",
    "        \"landingMarkerCategory\": boolean,\n",
    "        \"landingMarker\": \"H|V\",\n",
    "        \"markerScale\": number,\n",
    "        \"markerThickness\": number,\n",
    "        \"markerRotation\": number,\n",
    "        \"markerColor\": \"white|yellow|blue|red|green|black|purple|orange|gray|brown\",\n",
    "        \"letterThickness\": number,\n",
    "        \"tdpcCategory\": boolean,\n",
    "        \"tdpcType\": \"circle|cross|square\",\n",
    "        \"tdpcScale\": number,\n",
    "        \"tdpcThickness\": number,\n",
    "        \"tdpcRotation\": number,\n",
    "        \"tdpcExtrusion\": number,\n",
    "        \"tdpcColor\": \"white|yellow|blue|red|green|black|purple|orange|gray|brown\",\n",
    "        \"lightCategory\": boolean,\n",
    "        \"lightColor\": \"white|yellow|blue|red|green|black|purple|orange|gray|brown\",\n",
    "        \"lightScale\": number,\n",
    "        \"lightDistance\": number,\n",
    "        \"lightRadius\": number,\n",
    "        \"lightHeight\": number,\n",
    "        \"safetyAreaCategory\": boolean,\n",
    "        \"safetyAreaType\": \"offset|multiplier\",\n",
    "        \"dValue\": number,\n",
    "        \"multiplier\": number,\n",
    "        \"offsetDistance\": number,\n",
    "        \"safetyNetCategory\": boolean,\n",
    "        \"curveAngle\": number,\n",
    "        \"netHeight\": number,\n",
    "        \"safetyNetTransparency\": number,\n",
    "        \"safetyNetColor\": \"#FF0000\"\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "EXAMPLE:\n",
    "Input: \"rectangular TLOF for helicopter, 30x40m, elevation 5m, blue H marker\"\n",
    "Output: {\"TLOF\":[{\"position\":[0,0],\"dimensions\":{\"unit\":\"m\",\"aircraftCategory\":false,\"aircraft\":\"helicopter\",\"shapeType\":\"Rectangle\",\"width\":30,\"length\":40,\"baseHeight\":5,\"landingMarkerCategory\":true,\"landingMarker\":\"H\",\"markerColor\":\"blue\"}}]}\n",
    "\n",
    "Always respond with valid JSON only. Do not include explanations or markdown formatting.\"\"\"\n",
    "\n",
    "    def _extract_and_validate_json(self, response_content: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Extract and validate JSON from model response\n",
    "        \n",
    "        Args:\n",
    "            response_content: Raw response from the model\n",
    "            \n",
    "        Returns:\n",
    "            Parsed JSON dict or None if invalid\n",
    "        \"\"\"\n",
    "        # Try direct JSON parsing first\n",
    "        try:\n",
    "            tlof_config = json.loads(response_content)\n",
    "            if self._validate_tlof_structure(tlof_config):\n",
    "                return tlof_config\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "        \n",
    "        # Try to extract JSON from response (handle markdown, etc.)\n",
    "        json_patterns = [\n",
    "            r'\\{.*\\}',  # Simple brace matching\n",
    "            r'```json\\s*(\\{.*\\})\\s*```',  # Markdown code blocks\n",
    "            r'```\\s*(\\{.*\\})\\s*```',  # Generic code blocks\n",
    "        ]\n",
    "        \n",
    "        for pattern in json_patterns:\n",
    "            matches = re.findall(pattern, response_content, re.DOTALL)\n",
    "            for match in matches:\n",
    "                try:\n",
    "                    tlof_config = json.loads(match)\n",
    "                    if self._validate_tlof_structure(tlof_config):\n",
    "                        return tlof_config\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "        \n",
    "        logger.warning(\"‚ö†Ô∏è  Could not extract valid JSON from response\")\n",
    "        logger.debug(f\"Response content: {response_content[:500]}...\")\n",
    "        return None\n",
    "    \n",
    "    def _validate_tlof_structure(self, config: Dict[str, Any]) -> bool:\n",
    "        \"\"\"\n",
    "        Validate basic TLOF JSON structure\n",
    "        \n",
    "        Args:\n",
    "            config: Parsed JSON configuration\n",
    "            \n",
    "        Returns:\n",
    "            True if structure is valid\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Check top-level structure\n",
    "            if \"TLOF\" not in config:\n",
    "                return False\n",
    "            \n",
    "            if not isinstance(config[\"TLOF\"], list) or len(config[\"TLOF\"]) == 0:\n",
    "                return False\n",
    "            \n",
    "            # Check first TLOF entry\n",
    "            tlof = config[\"TLOF\"][0]\n",
    "            \n",
    "            required_keys = [\"position\", \"dimensions\"]\n",
    "            for key in required_keys:\n",
    "                if key not in tlof:\n",
    "                    return False\n",
    "            \n",
    "            # Validate position\n",
    "            if not isinstance(tlof[\"position\"], list) or len(tlof[\"position\"]) != 2:\n",
    "                return False\n",
    "            \n",
    "            # Validate dimensions is a dict\n",
    "            if not isinstance(tlof[\"dimensions\"], dict):\n",
    "                return False\n",
    "            \n",
    "            logger.info(\"‚úÖ TLOF structure validation passed\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"‚ö†Ô∏è  Structure validation failed: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def save_configuration(self, config: Dict[str, Any], filename: Optional[str] = None) -> str:\n",
    "        \"\"\"\n",
    "        Save TLOF configuration to file\n",
    "        \n",
    "        Args:\n",
    "            config: TLOF configuration dictionary\n",
    "            filename: Optional custom filename\n",
    "            \n",
    "        Returns:\n",
    "            Path to saved file\n",
    "        \"\"\"\n",
    "        if filename is None:\n",
    "            timestamp = int(time.time())\n",
    "            filename = f\"tlof_config_{timestamp}.json\"\n",
    "        \n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(config, f, indent=2)\n",
    "        \n",
    "        logger.info(f\"üíæ Configuration saved to: {filename}\")\n",
    "        return filename\n",
    "    \n",
    "    def batch_generate(self, inputs: list, output_dir: str = \"batch_outputs\") -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Generate multiple TLOF configurations in batch\n",
    "        \n",
    "        Args:\n",
    "            inputs: List of natural language descriptions\n",
    "            output_dir: Directory to save batch outputs\n",
    "            \n",
    "        Returns:\n",
    "            Summary of batch generation results\n",
    "        \"\"\"\n",
    "        logger.info(f\"üì¶ Starting batch generation for {len(inputs)} inputs...\")\n",
    "        \n",
    "        # Create output directory\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        results = {\n",
    "            \"total\": len(inputs),\n",
    "            \"successful\": 0,\n",
    "            \"failed\": 0,\n",
    "            \"outputs\": []\n",
    "        }\n",
    "        \n",
    "        for i, user_input in enumerate(inputs, 1):\n",
    "            logger.info(f\"üîÑ Processing {i}/{len(inputs)}: {user_input[:50]}...\")\n",
    "            \n",
    "            config = self.generate_tlof_configuration(user_input)\n",
    "            \n",
    "            if config:\n",
    "                # Save individual config\n",
    "                filename = os.path.join(output_dir, f\"tlof_config_{i:03d}.json\")\n",
    "                self.save_configuration(config, filename)\n",
    "                \n",
    "                results[\"successful\"] += 1\n",
    "                results[\"outputs\"].append({\n",
    "                    \"index\": i,\n",
    "                    \"input\": user_input,\n",
    "                    \"output_file\": filename,\n",
    "                    \"success\": True\n",
    "                })\n",
    "            else:\n",
    "                results[\"failed\"] += 1\n",
    "                results[\"outputs\"].append({\n",
    "                    \"index\": i,\n",
    "                    \"input\": user_input,\n",
    "                    \"output_file\": None,\n",
    "                    \"success\": False\n",
    "                })\n",
    "        \n",
    "        # Save batch summary\n",
    "        summary_file = os.path.join(output_dir, \"batch_summary.json\")\n",
    "        with open(summary_file, 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "        \n",
    "        logger.info(f\"üìä Batch generation completed:\")\n",
    "        logger.info(f\"   Successful: {results['successful']}\")\n",
    "        logger.info(f\"   Failed: {results['failed']}\")\n",
    "        logger.info(f\"   Summary saved to: {summary_file}\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Interactive TLOF generator - simplified version of the original notebook\n",
    "    \"\"\"\n",
    "    print(\"üöÄ TLOF Configuration Generator\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Using Azure OpenAI Fine-tuned Models\")\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        # Initialize generator\n",
    "        generator = TLOFGenerator()\n",
    "        \n",
    "        while True:\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"TLOF GENERATOR - Choose an option:\")\n",
    "            print(\"1. Generate single TLOF configuration\")\n",
    "            print(\"2. Batch generate from file\")\n",
    "            print(\"3. Test with sample prompts\")\n",
    "            print(\"4. Exit\")\n",
    "            print(\"=\"*50)\n",
    "            \n",
    "            choice = input(\"Enter your choice (1-4): \").strip()\n",
    "            \n",
    "            if choice == \"1\":\n",
    "                # Single generation\n",
    "                print(\"\\nüìù Describe your TLOF requirements in natural language:\")\n",
    "                print(\"Example: 'rectangular TLOF for helicopter, 25x30m, elevation 10m, blue H marker'\")\n",
    "                \n",
    "                user_input = input(\"\\nTLOF Description: \").strip()\n",
    "                \n",
    "                if user_input:\n",
    "                    print(f\"\\nü§ñ Using model: {generator.model_name}\")\n",
    "                    print(\"üîÑ Generating configuration...\")\n",
    "                    \n",
    "                    config = generator.generate_tlof_configuration(user_input)\n",
    "                    \n",
    "                    if config:\n",
    "                        print(\"\\n‚úÖ Generated TLOF Configuration:\")\n",
    "                        print(json.dumps(config, indent=2))\n",
    "                        \n",
    "                        # Save option\n",
    "                        save = input(\"\\nüíæ Save to file? (y/N): \").strip().lower()\n",
    "                        if save == 'y':\n",
    "                            filename = generator.save_configuration(config)\n",
    "                            print(f\"Saved to: {filename}\")\n",
    "                    else:\n",
    "                        print(\"‚ùå Failed to generate configuration. Please try again with a different description.\")\n",
    "                else:\n",
    "                    print(\"‚ö†Ô∏è  Please provide a description.\")\n",
    "            \n",
    "            elif choice == \"2\":\n",
    "                # Batch generation\n",
    "                file_path = input(\"Enter path to file with TLOF descriptions (one per line): \").strip()\n",
    "                \n",
    "                if os.path.exists(file_path):\n",
    "                    try:\n",
    "                        with open(file_path, 'r') as f:\n",
    "                            inputs = [line.strip() for line in f if line.strip()]\n",
    "                        \n",
    "                        if inputs:\n",
    "                            print(f\"üì¶ Found {len(inputs)} descriptions to process...\")\n",
    "                            results = generator.batch_generate(inputs)\n",
    "                            print(f\"‚úÖ Batch generation completed! Check 'batch_outputs' directory.\")\n",
    "                        else:\n",
    "                            print(\"‚ö†Ô∏è  File is empty or contains no valid descriptions.\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ùå Error reading file: {str(e)}\")\n",
    "                else:\n",
    "                    print(\"‚ùå File not found.\")\n",
    "            \n",
    "            elif choice == \"3\":\n",
    "                # Test with samples\n",
    "                print(\"\\nüß™ Testing with sample prompts...\")\n",
    "                \n",
    "                test_prompts = [\n",
    "                    \"Generate a rectangular TLOF for a helicopter with 25m x 30m dimensions, elevation 10m, and blue 'H' landing marker.\",\n",
    "                    \"Create a circular landing pad for an eVTOL with 20m diameter, white perimeter lighting, and safety area.\",\n",
    "                    \"Design a polygon TLOF for a tiltrotor aircraft with 6 sides, 35m width, red 'V' marker, and dashed markings.\",\n",
    "                    \"Build a simple rectangular TLOF for a drone with 8m x 8m dimensions at ground level.\"\n",
    "                ]\n",
    "                \n",
    "                for i, prompt in enumerate(test_prompts, 1):\n",
    "                    print(f\"\\nüìù Test {i}: {prompt}\")\n",
    "                    config = generator.generate_tlof_configuration(prompt)\n",
    "                    \n",
    "                    if config:\n",
    "                        print(f\"‚úÖ Test {i}: SUCCESS\")\n",
    "                        # Show basic info\n",
    "                        tlof = config[\"TLOF\"][0][\"dimensions\"]\n",
    "                        print(f\"   Aircraft: {tlof.get('aircraft', 'unknown')}\")\n",
    "                        print(f\"   Shape: {tlof.get('shapeType', 'unknown')}\")\n",
    "                        print(f\"   Size: {tlof.get('width', '?')}x{tlof.get('length', '?')}m\")\n",
    "                    else:\n",
    "                        print(f\"‚ùå Test {i}: FAILED\")\n",
    "                \n",
    "                print(\"\\nüèÅ Sample testing completed!\")\n",
    "            \n",
    "            elif choice == \"4\":\n",
    "                print(\"üëã Goodbye!\")\n",
    "                break\n",
    "            \n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è  Invalid choice. Please enter 1-4.\")\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nüõë Process interrupted by user\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"üí• Unexpected error: {str(e)}\")\n",
    "        print(f\"‚ùå Error: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
