{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b05d27b-b03d-4083-9e6a-c2f9089577f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting regulation_embedder_qa_app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile regulation_embedder_qa_app.py\n",
    "import os\n",
    "import sys\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "from typing import Optional\n",
    "from langchain_community.vectorstores import SupabaseVectorStore\n",
    "from supabase import create_client\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Supabase client\n",
    "supabase_url = os.getenv(\"SUPABASE_URL\")\n",
    "supabase_key = os.getenv(\"SUPABASE_KEY\")\n",
    "supabase = create_client(supabase_url, supabase_key)\n",
    "\n",
    "# Embeddings\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    model=os.getenv(\"AZURE_EMBEDDING_MODEL_NAME\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_EMBEDDING_ENDPOINT\"),\n",
    "    #openai_api_key=os.getenv(\"AZURE_EMBEDDING_API_KEY\"),\n",
    "    openai_api_version=\"2024-02-01\",\n",
    ")\n",
    "\n",
    "def build_vectorstore(file_paths: list[str], regulator_code: str) -> Optional[SupabaseVectorStore]:\n",
    "    \"\"\"Load PDFs, chunk them, and build a Supabase vectorstore in regulation_embd.\"\"\"\n",
    "    if not file_paths:\n",
    "        st.error(\"‚ùå No PDF files uploaded.\")\n",
    "        return None\n",
    "\n",
    "    documents = []\n",
    "    for file_path in file_paths:\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        documents.extend(loader.load())\n",
    "\n",
    "    if not documents:\n",
    "        st.warning(\"‚ö†Ô∏è No valid PDF documents found.\")\n",
    "        return None\n",
    "\n",
    "    # Split into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "\n",
    "    # Add regulator_code metadata\n",
    "    for doc in docs:\n",
    "        doc.metadata[\"regulator_code\"] = regulator_code\n",
    "\n",
    "    st.success(f\"‚úÖ Prepared {len(docs)} chunks for {regulator_code} regulations\")\n",
    "\n",
    "    # Push into Supabase\n",
    "    vs = SupabaseVectorStore.from_documents(\n",
    "        docs,\n",
    "        embeddings,\n",
    "        client=supabase,\n",
    "        table_name=\"regulation_embd\",\n",
    "        query_name=\"match_documents\",\n",
    "    )\n",
    "    return vs\n",
    "\n",
    "# ------------------ Streamlit UI ------------------\n",
    "st.title(\"üìò Regulation Embedding & RAG\")\n",
    "\n",
    "tab1, tab2 = st.tabs([\"üìÇ Embedding Uploader\", \"ü§ñ RAG Q&A\"])\n",
    "\n",
    "# ------------------ TAB 1: Embedding ------------------\n",
    "with tab1:\n",
    "    regulation_name = st.text_input(\"Enter Regulation Name (e.g. FAA):\", value=\"FAA\")\n",
    "\n",
    "    uploaded_files = st.file_uploader(\n",
    "        \"üìÇ Upload your PDF files\",\n",
    "        type=[\"pdf\"],\n",
    "        accept_multiple_files=True\n",
    "    )\n",
    "\n",
    "    file_paths = []\n",
    "    if uploaded_files:\n",
    "        save_dir = \"./uploaded_pdfs\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        for uploaded_file in uploaded_files:\n",
    "            file_path = os.path.join(save_dir, uploaded_file.name)\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                f.write(uploaded_file.getbuffer())\n",
    "            file_paths.append(file_path)\n",
    "\n",
    "        st.success(f\"‚úÖ {len(file_paths)} PDFs saved to {save_dir}\")\n",
    "\n",
    "    if st.button(\"üöÄ Start Embedding\", key=\"embedding_btn\"):\n",
    "        with st.spinner(\"Processing PDFs and uploading embeddings...\"):\n",
    "            vs = build_vectorstore(file_paths, regulation_name.lower())\n",
    "            if vs:\n",
    "                st.success(f\"üéâ {regulation_name} embeddings uploaded to Supabase table: regulation_embd\")\n",
    "            else:\n",
    "                st.error(\"‚ùå Could not build vectorstore. Please check your PDFs.\")\n",
    "\n",
    "# ------------------ TAB 2: RAG Q&A ------------------\n",
    "with tab2:\n",
    "    st.subheader(\"Ask Questions about Regulations\")\n",
    "\n",
    "    query = st.text_area(\"Enter your question:\", height=100)\n",
    "\n",
    "    if st.button(\"üîé Get Answer\", key=\"rag_btn\"):\n",
    "        with st.spinner(\"Fetching answer from RAG...\"):\n",
    "            # Reconnect to vectorstore\n",
    "            vs = SupabaseVectorStore(\n",
    "                client=supabase,\n",
    "                embedding=embeddings,\n",
    "                table_name=\"regulation_embd\",\n",
    "                query_name=\"match_documents\"\n",
    "            )\n",
    "            retriever = vs.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "            llm = AzureChatOpenAI(\n",
    "                azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "                api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "                api_version=\"2023-07-01-preview\",\n",
    "                model=os.getenv(\"AZURE_OPENAI_MODEL_NAME\"),\n",
    "                temperature=0\n",
    "            )\n",
    "\n",
    "            qa_chain = RetrievalQA.from_chain_type(\n",
    "                llm=llm,\n",
    "                retriever=retriever,\n",
    "                return_source_documents=True\n",
    "            )\n",
    "\n",
    "            result = qa_chain.invoke(query)\n",
    "\n",
    "            st.markdown(\"### üìù Answer\")\n",
    "            st.write(result[\"result\"])\n",
    "\n",
    "            st.markdown(\"### üìö Sources\")\n",
    "            for i, doc in enumerate(result[\"source_documents\"], 1):\n",
    "                st.markdown(f\"**Source {i}:** {doc.metadata}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d306b4f-fba1-4e3d-975c-78f79758f046",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run regulation_embedder_qa_app.py --server.port 8503 --server.headless true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e290c6ce-b597-489f-b251-d9c57945e005",
   "metadata": {},
   "source": [
    " [Launch App üöÄ](http://localhost:8503)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bfed61-b367-4fd5-b9ed-da3d5071e9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TLOF Size/Weight Limitation Box\n",
    "# what is the measurment for Relationship and Dimensions of TLOF, FATO, and Safety Area (Non-420 powered-lift)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
